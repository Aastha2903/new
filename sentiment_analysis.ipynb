{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN65HVpetxVpm1IjX4oO+aM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aastha2903/new/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiz6jIa6UxDO",
        "outputId": "871773a9-9cfc-4352-f127-1f53c026e9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZSA2FRcNudI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzAeHOh-D4Qs"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "\n",
        "API_KEY = 'bl5ajdr0V38G1JFT14iuECc2g'\n",
        "API_SECRET = 'GHH0hfYIqjRXrKVLrbexwa3Ldc7qLyjtdBTokgGFmD6reoV45J'\n",
        "ACCESS_TOKEN = '1863115926130003968-Ez2LlJESTR57WlJKvvdK9TrjTdk41v'\n",
        "ACCESS_TOKEN_SECRET = '7HtpzBfSl2YsGjlRkyA30tUhtxg3ZSAt6Et8DJCKbpKJ0'\n",
        "\n",
        "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
        "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-rz5wvTEUhtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAAOMnxQEAAAAAYgZ49rwC0LFwK0Vc9XNzYt6Jo5Q%3DNhdwexGzph3rR4AMiBIt5lNuetiInxV34tzo7eoF39VbIazfBg'\n",
        "\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "query = \"(stocks OR investing OR stock market OR finance OR trading OR shares OR mutual funds OR ETFs OR dividends OR IPO OR portfolio) lang:en -is:retweet has:links\"\n",
        "\n",
        "try:\n",
        "    response = client.search_recent_tweets(query=query, max_results=1, tweet_fields=['author_id', 'created_at'])\n",
        "\n",
        "    tweet_data = []\n",
        "\n",
        "    if response.data:\n",
        "        for tweet in response.data:\n",
        "            tweet_data.append({\n",
        "                'id': tweet.id,\n",
        "                'text': tweet.text,\n",
        "                'created_at': tweet.created_at\n",
        "            })\n",
        "        print(\"\\n--- Retrieved Tweet Data ---\")\n",
        "        print(tweet_data)\n",
        "    else:\n",
        "        print(\"\\nNo tweets found for the given query.\")\n",
        "\n",
        "except tweepy.TooManyRequests:\n",
        "    print(\"Rate limit exceeded. Please try again later.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "try:\n",
        "    tweets = client.search_recent_tweets(query=query, max_results= 20, tweet_fields=['author_id', 'created_at'])\n",
        "\n",
        "    tweet_data = []\n",
        "    if tweets.data:\n",
        "        for tweet in tweets.data:\n",
        "            tweet_data.append({\n",
        "                'id': tweet.id,\n",
        "                'text': tweet.text,\n",
        "                'created_at': tweet.created_at\n",
        "            })\n",
        "        print(\"\\n--- Retrieved Tweet Data ---\")\n",
        "        print(tweet_data)\n",
        "    else:\n",
        "        print(\"\\nNo tweets found for the given query.\")\n",
        "\n",
        "except tweepy.TooManyRequests:\n",
        "    print(\"Rate limit exceeded. Please try again later.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWJAF8bCVDUV",
        "outputId": "23132f2f-1a97-4fd4-c417-ca01e4dfc968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit exceeded. Please try again later.\n",
            "Rate limit exceeded. Please try again later.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVaRvziEX2eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    text = re.sub(r\"http\\S+|@\\S+|#\\S+|[^A-Za-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "cleaned_tweets =[]\n",
        "\n",
        "for tweet in tweet_data:\n",
        "\n",
        "    cleaned_text = clean_text(tweet['text'])\n",
        "\n",
        "    if len(cleaned_text) > 0:\n",
        "        cleaned_tweets.append({\n",
        "            'id': tweet['id'],\n",
        "            'cleaned_text': cleaned_text,\n",
        "            'original_text': tweet['text'],\n",
        "            'created_at': tweet['created_at']\n",
        "        })\n",
        "\n",
        "\n",
        "print(\"\\n--- Cleaned Tweet Data ---\")\n",
        "for tweet in cleaned_tweets:\n",
        "    print(tweet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "u6gtTLwHWCvC",
        "outputId": "6a7b3eeb-1817-4c9b-d98e-2186f3d5fd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tweet_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-422dd23c3005>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tweet_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "keywords = [\"stocks\", \"investing\", \"finance\", \"trading\", \"shares\", \"mutual funds\", \"ETFs\", \"dividends\", \"IPO\", \"portfolio\"]\n",
        "analysis_data = []\n",
        "mention_counter = Counter()\n",
        "for tweet in cleaned_tweets:\n",
        "    cleaned_text = tweet['cleaned_text']\n",
        "\n",
        "    analysis = TextBlob(cleaned_text)\n",
        "    sentiment_polarity = analysis.sentiment.polarity\n",
        "\n",
        "\n",
        "    mentions = [word.lower() for word in cleaned_text.split() if word.lower() in keywords]\n",
        "    mention_counter.update(mentions)\n",
        "\n",
        "    analysis_data.append({\n",
        "        'id': tweet['id'],\n",
        "        'cleaned_text': cleaned_text,\n",
        "        'original_text': tweet['original_text'],\n",
        "        'created_at': tweet['created_at'],\n",
        "        'sentiment_polarity': sentiment_polarity,\n",
        "        'mentions': mentions\n",
        "    })\n",
        "\n",
        "mention_summary = dict(mention_counter)\n",
        "\n",
        "print(\"\\n--- Analyzed Tweet Data ---\")\n",
        "for tweet in analysis_data:\n",
        "    print(tweet)\n",
        "\n",
        "print(\"\\n--- Keyword Mention Summary ---\")\n",
        "print(mention_summary)\n"
      ],
      "metadata": {
        "id": "mhXb6rrBYKIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "\n",
        "def get_stock_movement(created_at):\n",
        "\n",
        "    return random.choice([0, 1])\n",
        "\n",
        "data = []\n",
        "for tweet in analysis_data:\n",
        "    stock_movement = get_stock_movement(tweet['created_at'])\n",
        "    data.append({\n",
        "        'sentiment_polarity': tweet['sentiment_polarity'],\n",
        "        'mentions_count': len(tweet['mentions']),\n",
        "        'stock_movement': stock_movement\n",
        "    })\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['sentiment_polarity', 'mentions_count']]\n",
        "y = df['stock_movement']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IjmSfQghYtXP",
        "outputId": "bbffb1b5-4076-4433-8462-cfc88a66adb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'analysis_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8439c8e89f79>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalysis_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mstock_movement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stock_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     data.append({\n",
            "\u001b[0;31mNameError\u001b[0m: name 'analysis_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3ZScKsbFQTe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}